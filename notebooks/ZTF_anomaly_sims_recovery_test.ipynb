{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7683ef2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary packages\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "import matplotlib\n",
    "from matplotlib.transforms import Bbox\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "\n",
    "import astropy.table as at\n",
    "from astropy.table import MaskedColumn\n",
    "from astropy.io import fits\n",
    "from astropy.wcs import WCS\n",
    "from astropy.coordinates import SkyCoord\n",
    "from astropy.coordinates import Angle\n",
    "import astropy.units as u\n",
    "from astropy.visualization import PercentileInterval, AsinhStretch\n",
    "from astroquery.mast import Catalogs\n",
    "from astroquery.sdss import SDSS\n",
    "from astroquery.simbad import Simbad\n",
    "\n",
    "import light_curve as lc\n",
    "from itertools import chain\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import shutil\n",
    "import glob\n",
    "import json\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "plt.style.use('fig_publication.mplstyle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "087462ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions to extract light-curve features\n",
    "def replace_magn_with_flux(s):\n",
    "    if 'magnitude' in s:\n",
    "        return s.replace('magnitudes', 'fluxes').replace('magnitude', 'flux')\n",
    "    return f'{s} for flux light curve'\n",
    "\n",
    "def create_base_features_class(\n",
    "        magn_extractor,\n",
    "        flux_extractor,\n",
    "        bands=('R', 'g',),\n",
    "    ):\n",
    "    feature_names = ([f'{name}_magn' for name in magn_extractor.names]\n",
    "                     + [f'{name}_flux' for name in flux_extractor.names])\n",
    "    \n",
    "    property_names = {band: [f'feature_{name}_{band}'.lower()\n",
    "                             for name in feature_names]\n",
    "                      for band in bands}\n",
    "    \n",
    "    features_count = len(feature_names)\n",
    "    \n",
    "    return feature_names, property_names, features_count\n",
    "\n",
    "\n",
    "MAGN_EXTRACTOR = lc.Extractor(\n",
    "    lc.Amplitude(),\n",
    "    lc.AndersonDarlingNormal(),\n",
    "    lc.BeyondNStd(1.0),\n",
    "    lc.BeyondNStd(2.0),\n",
    "    lc.Cusum(),\n",
    "    lc.EtaE(),\n",
    "    lc.InterPercentileRange(0.02),\n",
    "    lc.InterPercentileRange(0.1),\n",
    "    lc.InterPercentileRange(0.25),\n",
    "    lc.Kurtosis(),\n",
    "    lc.LinearFit(),\n",
    "    lc.LinearTrend(),\n",
    "    lc.MagnitudePercentageRatio(0.4, 0.05),\n",
    "    lc.MagnitudePercentageRatio(0.2, 0.05),\n",
    "    lc.MaximumSlope(),\n",
    "    lc.Mean(),\n",
    "    lc.MedianAbsoluteDeviation(),\n",
    "    lc.PercentAmplitude(),\n",
    "    lc.PercentDifferenceMagnitudePercentile(0.05),\n",
    "    lc.PercentDifferenceMagnitudePercentile(0.1),\n",
    "    lc.MedianBufferRangePercentage(0.1),\n",
    "    lc.MedianBufferRangePercentage(0.2),\n",
    "    lc.Periodogram(\n",
    "        peaks=5,\n",
    "        resolution=10.0,\n",
    "        max_freq_factor=2.0,\n",
    "        nyquist='average',\n",
    "        fast=True,\n",
    "        features=(\n",
    "            lc.Amplitude(),\n",
    "            lc.BeyondNStd(2.0),\n",
    "            lc.BeyondNStd(3.0),\n",
    "            lc.StandardDeviation(),\n",
    "        ),\n",
    "    ),\n",
    "    lc.ReducedChi2(),\n",
    "    lc.Skew(),\n",
    "    lc.StandardDeviation(),\n",
    "    lc.StetsonK(),\n",
    "    lc.WeightedMean(),\n",
    ")\n",
    "\n",
    "FLUX_EXTRACTOR = lc.Extractor(\n",
    "    lc.AndersonDarlingNormal(),\n",
    "    lc.Cusum(),\n",
    "    lc.EtaE(),\n",
    "    lc.ExcessVariance(),\n",
    "    lc.Kurtosis(),\n",
    "    lc.MeanVariance(),\n",
    "    lc.ReducedChi2(),\n",
    "    lc.Skew(),\n",
    "    lc.StetsonK(),\n",
    ")\n",
    "\n",
    "def remove_simultaneous_alerts(table):\n",
    "    \"\"\"Remove alert duplicates\"\"\"\n",
    "    dt = np.diff(table['MJD'], append=np.inf)\n",
    "    return table[dt != 0]\n",
    "    \n",
    "def get_detections(photometry, band):\n",
    "    \"\"\"Extract clean light curve in given band from locus photometry\"\"\"\n",
    "    band_lc = photometry[(photometry['Filter'] == band) & (~photometry['MAG'].isna())]\n",
    "    idx = ~MaskedColumn(band_lc['MAG']).mask\n",
    "    detections = remove_simultaneous_alerts(band_lc[idx])\n",
    "    return detections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e9278acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_lc_features(k2, lightcurve):\n",
    "    \n",
    "\n",
    "    min_obs_count=4 # 4 is what model is trained on\n",
    "    lightcurve = lightcurve\n",
    "    \n",
    "    feature_names, property_names, features_count = create_base_features_class(MAGN_EXTRACTOR, FLUX_EXTRACTOR)\n",
    "\n",
    "    g_obs = list(get_detections(lightcurve, 'g').MJD.values)\n",
    "    r_obs = list(get_detections(lightcurve, 'R').MJD.values)\n",
    "    mjd_l = sorted(g_obs+r_obs)\n",
    "\n",
    "    lc_properties_d_l = []\n",
    "    len_det_counter_r,len_det_counter_g = 0,0\n",
    "\n",
    "    band_lc = lightcurve[(~lightcurve['MAG'].isna())]\n",
    "    idx = ~MaskedColumn(band_lc['MAG']).mask\n",
    "    all_detections = remove_simultaneous_alerts(band_lc[idx])\n",
    "    for ob, mjd in enumerate(mjd_l): # requires 4 obs\n",
    "        # do time evolution of detections - in chunks\n",
    "\n",
    "        detections_pb = all_detections[all_detections['MJD'].values <= mjd]\n",
    "        #print(detections)\n",
    "        lc_properties_d={}\n",
    "        for band, names in property_names.items():\n",
    "            detections = detections_pb[detections_pb['Filter'] == band]\n",
    "\n",
    "            # Ensure locus has >3 obs for calculation\n",
    "            if (len(detections) < min_obs_count):\n",
    "                continue\n",
    "            #print(detections)\n",
    "\n",
    "            t = detections['MJD'].values\n",
    "            m = detections['MAG'].values\n",
    "            merr = detections['MAGERR'].values\n",
    "            flux = np.power(10.0, -0.4 * m)\n",
    "            fluxerr = 0.5 * flux * (np.power(10.0, 0.4 * merr) - np.power(10.0, -0.4 * merr))\n",
    "\n",
    "            magn_features = MAGN_EXTRACTOR(\n",
    "                t,\n",
    "                m,\n",
    "                merr,\n",
    "                fill_value=None,\n",
    "            )\n",
    "            flux_features = FLUX_EXTRACTOR(\n",
    "                t,\n",
    "                flux,\n",
    "                fluxerr,\n",
    "                fill_value=None,\n",
    "            )\n",
    "\n",
    "            # After successfully calculating features, set locus properties and tag\n",
    "            lc_properties_d[\"obs_num\"] = int(ob)\n",
    "            lc_properties_d[\"mjd_cutoff\"] = mjd\n",
    "            lc_properties_d[\"k2\"] = k2\n",
    "            #print(band, m)\n",
    "            for name, value in zip(names, chain(magn_features, flux_features)):\n",
    "                lc_properties_d[name] = value\n",
    "                #if name == \"feature_amplitude_magn_g\": print(m, value, band)\n",
    "            #print(\"%%%%%%%%\")\n",
    "        lc_properties_d_l.append(lc_properties_d)\n",
    "\n",
    "    lc_properties_d_l = [d for d in lc_properties_d_l if d]\n",
    "    lc_properties_df = pd.DataFrame(lc_properties_d_l)\n",
    "    if len(lc_properties_df) == 0: \n",
    "        #print(f\"Not enough obs for {k2}. pass!\\n\")\n",
    "        return\n",
    "    #print(f\"Extracted LC features for {k2}!\")\n",
    "    \n",
    "    # Drop NaNs\n",
    "    lc_properties_df = lc_properties_df[~lc_properties_df.isnull().any(axis=1)].reset_index(drop=True)\n",
    "    \n",
    "    return lc_properties_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "39a644fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# From 106 available features from Kostya's lc_feature_extractor, use the 82 from SNAD Miner paper \n",
    "# R and g bands\n",
    "feature_names_r_g = ['feature_amplitude_magn_r', \n",
    "                 'feature_anderson_darling_normal_magn_r',\n",
    "                 'feature_beyond_1_std_magn_r', \n",
    "                 'feature_beyond_2_std_magn_r',\n",
    "                 'feature_cusum_magn_r', \n",
    "                 #'feature_eta_e_magn_r',\n",
    "                 'feature_inter_percentile_range_2_magn_r',\n",
    "                 'feature_inter_percentile_range_10_magn_r',\n",
    "                 'feature_inter_percentile_range_25_magn_r', \n",
    "                 'feature_kurtosis_magn_r',\n",
    "                 'feature_linear_fit_slope_magn_r',\n",
    "                 'feature_linear_fit_slope_sigma_magn_r',\n",
    "                 #'feature_linear_fit_reduced_chi2_magn_r', \n",
    "                 #'feature_linear_trend_magn_r', # cadence removal\n",
    "                 #'feature_linear_trend_sigma_magn_r',  # cadence removal\n",
    "                 'feature_magnitude_percentage_ratio_40_5_magn_r',\n",
    "                 'feature_magnitude_percentage_ratio_20_5_magn_r',\n",
    "                 #'feature_maximum_slope_magn_r',\n",
    "                 'feature_mean_magn_r',\n",
    "                 'feature_median_absolute_deviation_magn_r',\n",
    "                 'feature_percent_amplitude_magn_r',\n",
    "                 'feature_median_buffer_range_percentage_10_magn_r',\n",
    "                 'feature_median_buffer_range_percentage_20_magn_r',\n",
    "                 'feature_percent_difference_magnitude_percentile_5_magn_r',\n",
    "                 'feature_percent_difference_magnitude_percentile_10_magn_r',\n",
    "                 #'feature_period_0_magn_r',  # should be negated\n",
    "                 #'feature_period_s_to_n_0_magn_r', # cadence removal\n",
    "                 #'feature_period_1_magn_r', \n",
    "                 #'feature_period_s_to_n_1_magn_r', # cadence removal\n",
    "                 #'feature_period_2_magn_r', \n",
    "                 #'feature_period_s_to_n_2_magn_r', # cadence removal\n",
    "                 #'feature_period_3_magn_r', \n",
    "                 #'feature_period_s_to_n_3_magn_r', # cadence removal\n",
    "                 #'feature_period_4_magn_r', \n",
    "                 #'feature_period_s_to_n_4_magn_r', # cadence removal\n",
    "                 #'feature_periodogram_amplitude_magn_r',\n",
    "                 #'feature_periodogram_beyond_2_std_magn_r',  # cadence removal\n",
    "                 #'feature_periodogram_beyond_3_std_magn_r',  # cadence removal\n",
    "                 #'feature_periodogram_standard_deviation_magn_r',   # cadence removal\n",
    "                 #'feature_chi2_magn_r',\n",
    "                 'feature_skew_magn_r', \n",
    "                 'feature_standard_deviation_magn_r',\n",
    "                 'feature_stetson_k_magn_r',\n",
    "                 'feature_weighted_mean_magn_r',\n",
    "                 'feature_anderson_darling_normal_flux_r', \n",
    "                 'feature_cusum_flux_r',\n",
    "                 #'feature_eta_e_flux_r', \n",
    "                 'feature_excess_variance_flux_r',\n",
    "                 'feature_kurtosis_flux_r', \n",
    "                 'feature_mean_variance_flux_r',\n",
    "                 #'feature_chi2_flux_r', \n",
    "                 'feature_skew_flux_r',\n",
    "                 'feature_stetson_k_flux_r',\n",
    "\n",
    "                 'feature_amplitude_magn_g', \n",
    "                 'feature_anderson_darling_normal_magn_g',\n",
    "                 'feature_beyond_1_std_magn_g', \n",
    "                 'feature_beyond_2_std_magn_g',\n",
    "                 'feature_cusum_magn_g', \n",
    "                 #'feature_eta_e_magn_g',\n",
    "                 'feature_inter_percentile_range_2_magn_g',\n",
    "                 'feature_inter_percentile_range_10_magn_g',\n",
    "                 'feature_inter_percentile_range_25_magn_g', \n",
    "                 'feature_kurtosis_magn_g',\n",
    "                 'feature_linear_fit_slope_magn_g',\n",
    "                 'feature_linear_fit_slope_sigma_magn_g',\n",
    "                 #'feature_linear_fit_reduced_chi2_magn_g', \n",
    "                 #'feature_linear_trend_magn_g', # cadence removal\n",
    "                 #'feature_linear_trend_sigma_magn_g',  # cadence removal\n",
    "                 'feature_magnitude_percentage_ratio_40_5_magn_g',\n",
    "                 'feature_magnitude_percentage_ratio_20_5_magn_g',\n",
    "                 #'feature_maximum_slope_magn_g', \n",
    "                 'feature_mean_magn_g',\n",
    "                 'feature_median_absolute_deviation_magn_g',\n",
    "                 'feature_median_buffer_range_percentage_10_magn_g',\n",
    "                 'feature_median_buffer_range_percentage_20_magn_g',\n",
    "                 'feature_percent_amplitude_magn_g',\n",
    "                 'feature_percent_difference_magnitude_percentile_5_magn_g',\n",
    "                 'feature_percent_difference_magnitude_percentile_10_magn_g',\n",
    "                 #'feature_period_0_magn_g',  # should be negated\n",
    "                 #'feature_period_s_to_n_0_magn_g', # cadence removal\n",
    "                 #'feature_period_1_magn_g', \n",
    "                 #'feature_period_s_to_n_1_magn_g', # cadence removal\n",
    "                 #'feature_period_2_magn_g', \n",
    "                 #'feature_period_s_to_n_2_magn_g', # cadence removal\n",
    "                 #'feature_period_3_magn_g', \n",
    "                 #'feature_period_s_to_n_3_magn_g', # cadence removal\n",
    "                 #'feature_period_4_magn_g', \n",
    "                 #'feature_period_s_to_n_4_magn_g', # cadence removal\n",
    "                 #'feature_periodogram_amplitude_magn_g',\n",
    "                 #'feature_periodogram_beyond_2_std_magn_g',  # cadence removal\n",
    "                 #'feature_periodogram_beyond_3_std_magn_g', # cadence removal\n",
    "                 #'feature_periodogram_standard_deviation_magn_g',  # cadence removal\n",
    "                 #'feature_chi2_magn_g',\n",
    "                 'feature_skew_magn_g', \n",
    "                 'feature_standard_deviation_magn_g',\n",
    "                 'feature_stetson_k_magn_g', \n",
    "                 'feature_weighted_mean_magn_g',\n",
    "                 'feature_anderson_darling_normal_flux_g', \n",
    "                 'feature_cusum_flux_g',\n",
    "                 #'feature_eta_e_flux_g', \n",
    "                 'feature_excess_variance_flux_g',\n",
    "                 'feature_kurtosis_flux_g', \n",
    "                 'feature_mean_variance_flux_g',\n",
    "                 #'feature_chi2_flux_g', \n",
    "                 'feature_skew_flux_g',\n",
    "                 'feature_stetson_k_flux_g']   \n",
    "\n",
    "feature_names_hostgal = [\n",
    "    #  'Unnamed: 0',\n",
    "    #  'level_0',\n",
    "    #  'index',\n",
    "    #  'objName',\n",
    "    #  'objAltName1',\n",
    "    #  'objAltName2',\n",
    "    #  'objAltName3',\n",
    "    #  'objID',\n",
    "    #  'uniquePspsOBid',\n",
    "    #  'ippObjID',\n",
    "    #  'surveyID',\n",
    "    #  'htmID',\n",
    "    #  'zoneID',\n",
    "    #  'tessID',\n",
    "    #  'projectionID',\n",
    "    #  'skyCellID',\n",
    "    #  'randomID',\n",
    "    #  'batchID',\n",
    "    #  'dvoRegionID',\n",
    "    #  'processingVersion',\n",
    "    #  'objInfoFlag',\n",
    "    #  'qualityFlag',\n",
    "    #  'raStack',\n",
    "    #  'decStack',\n",
    "    #  'raStackErr',\n",
    "    #  'decStackErr',\n",
    "    #  'raMean',\n",
    "    #  'decMean',\n",
    "    #  'raMeanErr',\n",
    "    #  'decMeanErr',\n",
    "    #  'epochMean',\n",
    "    #  'posMeanChisq',\n",
    "    #  'cx',\n",
    "    #  'cy',\n",
    "    #  'cz',\n",
    "    #  'lambda',\n",
    "    #  'beta',\n",
    "    #  'l',\n",
    "    #  'b',\n",
    "    #  'nStackObjectRows',\n",
    "    #  'nStackDetections',\n",
    "    #  'nDetections',\n",
    "    #  'ng',\n",
    "    #  'nr',\n",
    "    #  'ni',\n",
    "    #  'nz',\n",
    "    #  'ny',\n",
    "    #  'uniquePspsSTid',\n",
    "    #  'primaryDetection',\n",
    "    #  'bestDetection',\n",
    "    #  'gippDetectID',\n",
    "    #  'gstackDetectID',\n",
    "    #  'gstackImageID',\n",
    "    #  'gra',\n",
    "    #  'gdec',\n",
    "    #  'graErr',\n",
    "    #  'gdecErr',\n",
    "    #  'gEpoch',\n",
    "    #  'gPSFMag',\n",
    "    #  'gPSFMagErr',\n",
    "    #  'gApMag',\n",
    "    #  'gApMagErr',\n",
    "    #  'gKronMag',\n",
    "    #  'gKronMagErr',\n",
    "    #  'ginfoFlag',\n",
    "    #  'ginfoFlag2',\n",
    "    #  'ginfoFlag3',\n",
    "    #  'gnFrames',\n",
    "    #  'gxPos',\n",
    "    #  'gyPos',\n",
    "    #  'gxPosErr',\n",
    "    #  'gyPosErr',\n",
    "    #  'gpsfMajorFWHM',\n",
    "    #  'gpsfMinorFWHM',\n",
    "    #  'gpsfTheta',\n",
    "    #  'gpsfCore',\n",
    "    #  'gpsfLikelihood',\n",
    "    #  'gpsfQf',\n",
    "    #  'gpsfQfPerfect',\n",
    "    #  'gpsfChiSq',\n",
    "     'gmomentXX',\n",
    "     'gmomentXY',\n",
    "     'gmomentYY',\n",
    "     'gmomentR1',\n",
    "     'gmomentRH',\n",
    "     'gPSFFlux',\n",
    "    #  'gPSFFluxErr',\n",
    "     'gApFlux',\n",
    "    #  'gApFluxErr',\n",
    "    #  'gApFillFac',\n",
    "    #  'gApRadius',\n",
    "     'gKronFlux',\n",
    "    #  'gKronFluxErr',\n",
    "     'gKronRad',\n",
    "    #  'gexpTime',\n",
    "     'gExtNSigma',\n",
    "    #  'gsky',\n",
    "    #  'gskyErr',\n",
    "    #  'gzp',\n",
    "    #  'gPlateScale',\n",
    "    #  'rippDetectID',\n",
    "    #  'rstackDetectID',\n",
    "    #  'rstackImageID',\n",
    "    #  'rra',\n",
    "    #  'rdec',\n",
    "    #  'rraErr',\n",
    "    #  'rdecErr',\n",
    "    #  'rEpoch',\n",
    "    # 'rPSFMag',\n",
    "    #  'rPSFMagErr',\n",
    "    # 'rApMag',\n",
    "    #  'rApMagErr',\n",
    "    # 'rKronMag',\n",
    "    #  'rKronMagErr',\n",
    "    #  'rinfoFlag',\n",
    "    #  'rinfoFlag2',\n",
    "    #  'rinfoFlag3',\n",
    "    #  'rnFrames',\n",
    "    #  'rxPos',\n",
    "    #  'ryPos',\n",
    "    #  'rxPosErr',\n",
    "    #  'ryPosErr',\n",
    "    #  'rpsfMajorFWHM',\n",
    "    #  'rpsfMinorFWHM',\n",
    "    #  'rpsfTheta',\n",
    "    #  'rpsfCore',\n",
    "    #  'rpsfLikelihood',\n",
    "    #  'rpsfQf',\n",
    "    #  'rpsfQfPerfect',\n",
    "    #  'rpsfChiSq',\n",
    "     'rmomentXX',\n",
    "     'rmomentXY',\n",
    "     'rmomentYY',\n",
    "     'rmomentR1',\n",
    "     'rmomentRH',\n",
    "    'rPSFFlux',\n",
    "    #  'rPSFFluxErr',\n",
    "    'rApFlux',\n",
    "    #  'rApFluxErr',\n",
    "    #  'rApFillFac',\n",
    "    # 'rApRadius',\n",
    "    'rKronFlux',\n",
    "    #  'rKronFluxErr',\n",
    "    'rKronRad',\n",
    "    #  'rexpTime',\n",
    "     'rExtNSigma',\n",
    "    #  'rsky',\n",
    "    #  'rskyErr',\n",
    "    #  'rzp',\n",
    "    #  'rPlateScale',\n",
    "    #  'iippDetectID',\n",
    "    #  'istackDetectID',\n",
    "    #  'istackImageID',\n",
    "    #  'ira',\n",
    "    #  'idec',\n",
    "    #  'iraErr',\n",
    "    #  'idecErr',\n",
    "    #  'iEpoch',\n",
    "    #  'iPSFMag',\n",
    "    #  'iPSFMagErr',\n",
    "    #  'iApMag',\n",
    "    #  'iApMagErr',\n",
    "    #  'iKronMag',\n",
    "    #  'iKronMagErr',\n",
    "    #  'iinfoFlag',\n",
    "    #  'iinfoFlag2',\n",
    "    #  'iinfoFlag3',\n",
    "    #  'inFrames',\n",
    "    #  'ixPos',\n",
    "    #  'iyPos',\n",
    "    #  'ixPosErr',\n",
    "    #  'iyPosErr',\n",
    "    #  'ipsfMajorFWHM',\n",
    "    #  'ipsfMinorFWHM',\n",
    "    #  'ipsfTheta',\n",
    "    #  'ipsfCore',\n",
    "    #  'ipsfLikelihood',\n",
    "    #  'ipsfQf',\n",
    "    #  'ipsfQfPerfect',\n",
    "    #  'ipsfChiSq',\n",
    "      'imomentXX',\n",
    "     'imomentXY',\n",
    "     'imomentYY',\n",
    "     'imomentR1',\n",
    "     'imomentRH',\n",
    "     'iPSFFlux',\n",
    "    #  'iPSFFluxErr',\n",
    "     'iApFlux',\n",
    "    #  'iApFluxErr',\n",
    "    #  'iApFillFac',\n",
    "    #  'iApRadius',\n",
    "     'iKronFlux',\n",
    "    #  'iKronFluxErr',\n",
    "     'iKronRad',\n",
    "    #  'iexpTime',\n",
    "      'iExtNSigma',\n",
    "    #  'isky',\n",
    "    #  'iskyErr',\n",
    "    #  'izp',\n",
    "    #  'iPlateScale',\n",
    "    #  'zippDetectID',\n",
    "    #  'zstackDetectID',\n",
    "    #  'zstackImageID',\n",
    "    #  'zra',\n",
    "    #  'zdec',\n",
    "    #  'zraErr',\n",
    "    #  'zdecErr',\n",
    "    #  'zEpoch',\n",
    "    #  'zPSFMag',\n",
    "    #  'zPSFMagErr',\n",
    "    #  'zApMag',\n",
    "    #  'zApMagErr',\n",
    "    #  'zKronMag',\n",
    "    #  'zKronMagErr',\n",
    "    #  'zinfoFlag',\n",
    "    #  'zinfoFlag2',\n",
    "    #  'zinfoFlag3',\n",
    "    #  'znFrames',\n",
    "    #  'zxPos',\n",
    "    #  'zyPos',\n",
    "    #  'zxPosErr',\n",
    "    #  'zyPosErr',\n",
    "    #  'zpsfMajorFWHM',\n",
    "    #  'zpsfMinorFWHM',\n",
    "    #  'zpsfTheta',\n",
    "    #  'zpsfCore',\n",
    "    #  'zpsfLikelihood',\n",
    "    #  'zpsfQf',\n",
    "    #  'zpsfQfPerfect',\n",
    "    #  'zpsfChiSq',\n",
    "      'zmomentXX',\n",
    "     'zmomentXY',\n",
    "     'zmomentYY',\n",
    "     'zmomentR1',\n",
    "     'zmomentRH',\n",
    "     'zPSFFlux',\n",
    "    # #  'zPSFFluxErr',\n",
    "     'zApFlux',\n",
    "    # #  'zApFluxErr',\n",
    "    # #  'zApFillFac',\n",
    "    # #  'zApRadius',\n",
    "     'zKronFlux',\n",
    "    # #  'zKronFluxErr',\n",
    "     'zKronRad',\n",
    "    # #  'zexpTime',\n",
    "      'zExtNSigma',\n",
    "    #  'zsky',\n",
    "    #  'zskyErr',\n",
    "    #  'zzp',\n",
    "    #  'zPlateScale',\n",
    "    #  'yippDetectID',\n",
    "    #  'ystackDetectID',\n",
    "    #  'ystackImageID',\n",
    "    #  'yra',\n",
    "    #  'ydec',\n",
    "    #  'yraErr',\n",
    "    #  'ydecErr',\n",
    "    #  'yEpoch',\n",
    "    #  'yPSFMag',\n",
    "    #  'yPSFMagErr',\n",
    "    #  'yApMag',\n",
    "    #  'yApMagErr',\n",
    "    #  'yKronMag',\n",
    "    #  'yKronMagErr',\n",
    "    #  'yinfoFlag',\n",
    "    #  'yinfoFlag2',\n",
    "    #  'yinfoFlag3',\n",
    "    #  'ynFrames',\n",
    "    #  'yxPos',\n",
    "    #  'yyPos',\n",
    "    #  'yxPosErr',\n",
    "    #  'yyPosErr',\n",
    "    #  'ypsfMajorFWHM',\n",
    "    #  'ypsfMinorFWHM',\n",
    "    #  'ypsfTheta',\n",
    "    #  'ypsfCore',\n",
    "    #  'ypsfLikelihood',\n",
    "    #  'ypsfQf',\n",
    "    #  'ypsfQfPerfect',\n",
    "    #  'ypsfChiSq',\n",
    "      'ymomentXX',\n",
    "      'ymomentXY',\n",
    "      'ymomentYY',\n",
    "      'ymomentR1',\n",
    "      'ymomentRH',\n",
    "      'yPSFFlux',\n",
    "    # #   'yPSFFluxErr',\n",
    "      'yApFlux',\n",
    "    # #   'yApFluxErr',\n",
    "    # #   'yApFillFac',\n",
    "    # #  'yApRadius',\n",
    "     'yKronFlux',\n",
    "    # #  'yKronFluxErr',\n",
    "     'yKronRad',\n",
    "    # #  'yexpTime',\n",
    "      'yExtNSigma',\n",
    "    #  'ysky',\n",
    "    #  'yskyErr',\n",
    "    #  'yzp',\n",
    "    #  'yPlateScale',\n",
    "    #  'distance',\n",
    "    #  'SkyMapper_StarClass',\n",
    "    #  'gelong',\n",
    "    #  'g_a',\n",
    "    #  'g_b',\n",
    "    #  'g_pa',\n",
    "    #  'relong',\n",
    "    #  'r_a',\n",
    "    #  'r_b',\n",
    "    #  'r_pa',\n",
    "    #  'ielong',\n",
    "    #  'i_a',\n",
    "    #  'i_b',\n",
    "    #  'i_pa',\n",
    "    #  'zelong',\n",
    "    #  'z_a',\n",
    "    #  'z_b',\n",
    "    #  'z_pa',\n",
    "       'i-z', # try throwing in\n",
    "    #    'g-r',\n",
    "    #    'r-i',\n",
    "    #    'g-i',\n",
    "    #    'z-y',\n",
    "    #   'g-rErr',\n",
    "    #   'r-iErr',\n",
    "    #   'i-zErr',\n",
    "    #   'z-yErr',\n",
    "     'gApMag_gKronMag',\n",
    "     'rApMag_rKronMag',\n",
    "     'iApMag_iKronMag',\n",
    "     'zApMag_zKronMag',\n",
    "     'yApMag_yKronMag',\n",
    "     '7DCD', \n",
    "    #  'NED_name',\n",
    "    #  'NED_type',\n",
    "    #  'NED_vel',\n",
    "    #  'NED_redshift',\n",
    "    #  'NED_mag',\n",
    "    #  'class',\n",
    "       'dist/DLR',\n",
    "    #   'dist',\n",
    "    #  'TransientClass',\n",
    "    #  'TransientRA',\n",
    "    #  'TransientDEC'\n",
    "       ]\n",
    "\n",
    "\n",
    "lc_and_host_features = feature_names_r_g + feature_names_hostgal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "456fa562",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters for best AD model\n",
    "n_estimators=100 \n",
    "max_depth=35 \n",
    "random_state=11\n",
    "max_features=35 # {“sqrt”, “log2”, None}, int or float, default=”sqrt” - sqrt(120) ~ 10\n",
    "class_weight={\"Normal\": 1, \"Other\": 1} #\"balanced\"\n",
    "\n",
    "model_path = f\"/Users/patrickaleo/Desktop/Illinois/LAISS-antares/repo/RFC/SMOTE_train_test_70-30_min14_kneighbors8/cls=binary_n_estimators={n_estimators}_max_depth={max_depth}_rs={random_state}_max_feats={max_features}_cw=balanced/model\"\n",
    "    \n",
    "with open(f'{model_path}/cls=binary_n_estimators={n_estimators}_max_depth={max_depth}_rs={random_state}_max_feats={max_features}_cw=balanced.pkl', 'rb') as f:\n",
    "    clf = pickle.load(f)\n",
    "\n",
    "\n",
    "def plot_RFC_prob_vs_lc_ztfid(clf, k2, cls, photoz, anom_thresh, lc_and_hosts_df, lc_and_hosts_df_120d, lightcurve, savefig, figure_path, plot=False):\n",
    "    anom_thresh = anom_thresh\n",
    "    anom_obj_df = lc_and_hosts_df_120d\n",
    "\n",
    "    try:\n",
    "        pred_prob_anom = 100 * clf.predict_proba(anom_obj_df)\n",
    "        pred_prob_anom[:, 0] = [round(a, 1) for a in pred_prob_anom[:, 0]]\n",
    "        pred_prob_anom[:, 1] = [round(b, 1) for b in pred_prob_anom[:, 1]]\n",
    "        num_anom_epochs = len(np.where(pred_prob_anom[:, 1]>=anom_thresh)[0])\n",
    "    except:\n",
    "        #print(f\"{k2} has some NaN host galaxy values from PS1 catalog. Skip!\")\n",
    "        return\n",
    "\n",
    "    try: \n",
    "        anom_idx = lc_and_hosts_df.iloc[np.where(pred_prob_anom[:, 1]>=anom_thresh)[0][0]].obs_num\n",
    "        anom_idx_is = True\n",
    "        #print(\"Anomalous during timeseries!\")\n",
    "\n",
    "    except: \n",
    "        #print(f\"Prediction doesn't exceed anom_threshold of {anom_thresh}% for {k2}.\")\n",
    "        anom_idx_is = False\n",
    "\n",
    "    max_anom_score = max(pred_prob_anom[:, 1])\n",
    "    #print(\"max_anom_score\", round(max_anom_score, 1))\n",
    "    #print(\"num_anom_epochs\", num_anom_epochs)\n",
    "    \n",
    "    if plot:\n",
    "        df_ref = lightcurve\n",
    "\n",
    "        df_ref_g = df_ref[(df_ref.Filter == 'g') & (~df_ref.MAG.isna())]\n",
    "        df_ref_r = df_ref[(df_ref.Filter == 'R') & (~df_ref.MAG.isna())]\n",
    "\n",
    "        mjd_idx_at_min_mag_r_ref = df_ref_r[['MAG']].reset_index().idxmin().MAG\n",
    "        mjd_idx_at_min_mag_g_ref = df_ref_g[['MAG']].reset_index().idxmin().MAG\n",
    "\n",
    "        fig, (ax1, ax2) = plt.subplots(2, 1, sharex=True, figsize=(7,10))\n",
    "        ax1.invert_yaxis()\n",
    "        ax1.errorbar(x=df_ref_r.MJD, y=df_ref_r.MAG, yerr=df_ref_r.MAGERR, fmt='o', c='r', label=r'ZTF-$r$')\n",
    "        ax1.errorbar(x=df_ref_g.MJD, y=df_ref_g.MAG, yerr=df_ref_g.MAGERR, fmt='o', c='g', label=r'ZTF-$g$')\n",
    "        if anom_idx_is == True:\n",
    "            ax1.axvline(x=lc_and_hosts_df[lc_and_hosts_df.obs_num == anom_idx].mjd_cutoff.values[0], \n",
    "                        label=\"Tagged anomalous\", color='darkblue', ls='--')\n",
    "            mjd_cross_thresh = round(lc_and_hosts_df[lc_and_hosts_df.obs_num == anom_idx].mjd_cutoff.values[0], 3)\n",
    "\n",
    "            left, right = ax1.get_xlim()\n",
    "            mjd_anom_per = (mjd_cross_thresh - left)/(right - left)\n",
    "            plt.text(mjd_anom_per+0.073, -0.075, f\"t = {int(mjd_cross_thresh)}\", horizontalalignment='center',\n",
    "             verticalalignment='center', transform=ax1.transAxes, fontsize=16)\n",
    "            print(\"MJD crossed thresh:\", mjd_cross_thresh)\n",
    "\n",
    "        ax2.plot(lc_and_hosts_df.mjd_cutoff, pred_prob_anom[:, 0], label=r'$p(Normal)$')\n",
    "        ax2.plot(lc_and_hosts_df.mjd_cutoff, pred_prob_anom[:, 1], label=r'$p(Anomaly)$')\n",
    "\n",
    "        ax1.set_title(fr\"{k2} ({cls}, $photo-z$={photoz})\" , pad=25)\n",
    "        plt.xlabel('MJD')\n",
    "        ax1.set_ylabel('Magnitude')\n",
    "        ax2.set_ylabel('Probability (%)')\n",
    "\n",
    "        if anom_idx_is == True: ax1.legend(loc='upper right', ncol=3, bbox_to_anchor=(1.0,1.12), frameon=False, fontsize=14)\n",
    "        else: ax1.legend(loc='upper right', ncol=2, bbox_to_anchor=(0.75,1.12), frameon=False, fontsize=14)\n",
    "        ax2.legend(loc='upper right', ncol=2, bbox_to_anchor=(0.87,1.12), frameon=False, fontsize=14)\n",
    "\n",
    "        ax1.grid(True)\n",
    "        ax2.grid(True)\n",
    "\n",
    "        if savefig:\n",
    "            plt.savefig(f\"{figure_path}/{k2}_{cls}_AD_run_timeseries.pdf\", dpi=300, bbox_inches='tight')\n",
    "\n",
    "        plt.show()\n",
    "    \n",
    "    if anom_idx_is == True:\n",
    "        anom_idx_is = \"Anomaly\"\n",
    "    elif anom_idx_is == False:\n",
    "        anom_idx_is = \"Normal\"\n",
    "    else: \n",
    "        anom_idx_is = \"???\"\n",
    "        \n",
    "    return k2, anom_idx_is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d7b13a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "efeefc7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Specify the path to your JSON file\n",
    "json_file_path = 'ZTF_sims_from_Alex/ZTFAnomalies_FORPALEO.json'\n",
    "\n",
    "# Open the JSON file for reading\n",
    "with open(json_file_path, 'r', encoding='utf-8') as json_file:\n",
    "    # Initialize an empty list to store parsed data\n",
    "    data_list = []\n",
    "\n",
    "    # Iterate over the lines in the file to read and parse each JSON object\n",
    "    for line in json_file:\n",
    "        try:\n",
    "            # Load and parse the JSON object from the current line\n",
    "            data = json.loads(line)\n",
    "            \n",
    "            # Append the parsed data to the list\n",
    "            data_list.append(data)\n",
    "        except json.JSONDecodeError as e:\n",
    "            print(f\"Error parsing JSON: {str(e)}\")\n",
    "            continue\n",
    "\n",
    "# Now, 'data_list' contains all the parsed data from the JSON file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4a55af81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'HOSTGAL_MAG_z', 'HOSTGAL_MAG_g', 'HOSTGAL_MAG_i', 'Flux_Err', 'MAGERR', 'HOSTGAL_MAGERR_r', 'SIM_HOSTLIB_GALID', 'MAG', 'HOSTGAL_PHOTOZ', 'HOSTGAL_MAGERR_g', 'HOSTGAL_PHOTOZ_ERR', 'HOSTGAL_MAG_r', 'REDSHIFT_HELIO', 'MJD', 'HOSTGAL_MAGERR_i', 'Flux', 'MJD_TRIGGER', 'MWEBV', 'Filter', 'Type', 'HOSTGAL_MAGERR_z', 'HOSTGAL_DDLR'}\n"
     ]
    }
   ],
   "source": [
    "# Assuming 'data_list' contains your parsed JSON data\n",
    "\n",
    "# Initialize an empty set to store unique keys\n",
    "all_keys = set()\n",
    "\n",
    "# Iterate through the parsed data\n",
    "for item in data_list:\n",
    "    # Check if the item is a dictionary (JSON object)\n",
    "    if isinstance(item, dict):\n",
    "        # Update the set of keys with the keys from this dictionary\n",
    "        all_keys.update(item.keys())\n",
    "\n",
    "# Now, 'all_keys' contains all the unique keys present in your JSON data\n",
    "print(all_keys)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "244b5a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "anomaly_distr_d = {'PISN-STELLA_HYDROGENIC': 978,\n",
    "         'TDE': 985,\n",
    "         'KN_B19': 2,\n",
    "         'SNIIn-MOSFIT': 242,\n",
    "         'SNIa-91bg': 1023,\n",
    "         'SNIax': 239,\n",
    "         'SNIIn+HostXT': 1774,\n",
    "         'SNII': 2330,\n",
    "         'CART': 90,\n",
    "         'PISN-STELLA_HECORE': 595,\n",
    "         'SLSNI': 4166,\n",
    "         'PISN-MOSFIT': 4152,\n",
    "         'SNIb': 989,\n",
    "         'SNIa': 3530,\n",
    "         'SNIcBL+HostXT_V19': 1145,\n",
    "         'SNIc': 2532,\n",
    "         'ILOT': 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4abbf622",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['CART', 'ILOT', 'KN_B19', 'PISN-MOSFIT', 'PISN-STELLA_HECORE',\n",
       "       'PISN-STELLA_HYDROGENIC', 'SLSNI', 'SNII', 'SNIIn+HostXT',\n",
       "       'SNIIn-MOSFIT', 'SNIa', 'SNIa-91bg', 'SNIax', 'SNIb', 'SNIc',\n",
       "       'SNIcBL+HostXT_V19', 'TDE'], dtype='<U22')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uniq_cls_l = np.unique(list(data['Type'].values()))\n",
    "uniq_cls_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0d720698",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gmomentXX</th>\n",
       "      <th>gmomentXY</th>\n",
       "      <th>gmomentYY</th>\n",
       "      <th>gmomentR1</th>\n",
       "      <th>gmomentRH</th>\n",
       "      <th>gPSFFlux</th>\n",
       "      <th>gApFlux</th>\n",
       "      <th>gKronFlux</th>\n",
       "      <th>gKronRad</th>\n",
       "      <th>gExtNSigma</th>\n",
       "      <th>...</th>\n",
       "      <th>yKronRad</th>\n",
       "      <th>yExtNSigma</th>\n",
       "      <th>i-z</th>\n",
       "      <th>gApMag_gKronMag</th>\n",
       "      <th>rApMag_rKronMag</th>\n",
       "      <th>iApMag_iKronMag</th>\n",
       "      <th>zApMag_zKronMag</th>\n",
       "      <th>yApMag_yKronMag</th>\n",
       "      <th>7DCD</th>\n",
       "      <th>dist/DLR</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ztf_object_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ZTF17aaadars</th>\n",
       "      <td>0.182697</td>\n",
       "      <td>0.000057</td>\n",
       "      <td>0.206433</td>\n",
       "      <td>0.899402</td>\n",
       "      <td>0.707021</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>2.24851</td>\n",
       "      <td>-0.771992</td>\n",
       "      <td>...</td>\n",
       "      <td>2.28946</td>\n",
       "      <td>0.923409</td>\n",
       "      <td>0.257099</td>\n",
       "      <td>-0.120399</td>\n",
       "      <td>-0.177700</td>\n",
       "      <td>-0.116199</td>\n",
       "      <td>-0.128300</td>\n",
       "      <td>-0.208900</td>\n",
       "      <td>48.409333</td>\n",
       "      <td>0.063386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ZTF17aaahrni</th>\n",
       "      <td>0.395019</td>\n",
       "      <td>0.035295</td>\n",
       "      <td>0.428865</td>\n",
       "      <td>1.574710</td>\n",
       "      <td>0.911899</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>3.93677</td>\n",
       "      <td>8.333380</td>\n",
       "      <td>...</td>\n",
       "      <td>2.43505</td>\n",
       "      <td>6.442500</td>\n",
       "      <td>0.096600</td>\n",
       "      <td>0.164299</td>\n",
       "      <td>-0.071001</td>\n",
       "      <td>0.051300</td>\n",
       "      <td>-0.024000</td>\n",
       "      <td>-0.145601</td>\n",
       "      <td>22.882911</td>\n",
       "      <td>2.639232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ZTF17aaaizmo</th>\n",
       "      <td>0.280209</td>\n",
       "      <td>0.020304</td>\n",
       "      <td>0.289936</td>\n",
       "      <td>3.348710</td>\n",
       "      <td>1.155740</td>\n",
       "      <td>0.000057</td>\n",
       "      <td>0.000141</td>\n",
       "      <td>0.000310</td>\n",
       "      <td>8.37179</td>\n",
       "      <td>15.204500</td>\n",
       "      <td>...</td>\n",
       "      <td>5.85443</td>\n",
       "      <td>28.151199</td>\n",
       "      <td>0.027800</td>\n",
       "      <td>0.855101</td>\n",
       "      <td>0.652599</td>\n",
       "      <td>0.618401</td>\n",
       "      <td>0.684500</td>\n",
       "      <td>0.695499</td>\n",
       "      <td>14.803999</td>\n",
       "      <td>4.788567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ZTF17aabtbti</th>\n",
       "      <td>0.345283</td>\n",
       "      <td>-0.014541</td>\n",
       "      <td>0.300773</td>\n",
       "      <td>1.260110</td>\n",
       "      <td>0.941188</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>3.15028</td>\n",
       "      <td>4.822180</td>\n",
       "      <td>...</td>\n",
       "      <td>2.25483</td>\n",
       "      <td>3.383140</td>\n",
       "      <td>0.175501</td>\n",
       "      <td>-0.055199</td>\n",
       "      <td>0.066099</td>\n",
       "      <td>-0.006701</td>\n",
       "      <td>-0.024200</td>\n",
       "      <td>-0.064001</td>\n",
       "      <td>5.578753</td>\n",
       "      <td>11.742125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ZTF17aachsxt</th>\n",
       "      <td>0.330886</td>\n",
       "      <td>0.020398</td>\n",
       "      <td>0.289500</td>\n",
       "      <td>1.696890</td>\n",
       "      <td>1.039760</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>0.000046</td>\n",
       "      <td>0.000051</td>\n",
       "      <td>4.24223</td>\n",
       "      <td>18.275499</td>\n",
       "      <td>...</td>\n",
       "      <td>3.51504</td>\n",
       "      <td>20.063499</td>\n",
       "      <td>-0.094900</td>\n",
       "      <td>0.122499</td>\n",
       "      <td>0.208000</td>\n",
       "      <td>0.324200</td>\n",
       "      <td>0.378099</td>\n",
       "      <td>0.192301</td>\n",
       "      <td>45.767392</td>\n",
       "      <td>4.255986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ZTF22aaboeex</th>\n",
       "      <td>0.308624</td>\n",
       "      <td>0.007761</td>\n",
       "      <td>0.309511</td>\n",
       "      <td>3.498180</td>\n",
       "      <td>1.136470</td>\n",
       "      <td>0.000074</td>\n",
       "      <td>0.000165</td>\n",
       "      <td>0.000340</td>\n",
       "      <td>8.74544</td>\n",
       "      <td>24.032301</td>\n",
       "      <td>...</td>\n",
       "      <td>6.76913</td>\n",
       "      <td>26.586201</td>\n",
       "      <td>0.233500</td>\n",
       "      <td>0.784500</td>\n",
       "      <td>0.708401</td>\n",
       "      <td>0.683500</td>\n",
       "      <td>0.644199</td>\n",
       "      <td>0.548500</td>\n",
       "      <td>25.406284</td>\n",
       "      <td>1.134230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ZTF22aaboiqa</th>\n",
       "      <td>0.271177</td>\n",
       "      <td>0.036831</td>\n",
       "      <td>0.286689</td>\n",
       "      <td>1.241780</td>\n",
       "      <td>0.951537</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>0.000047</td>\n",
       "      <td>0.000045</td>\n",
       "      <td>3.10445</td>\n",
       "      <td>7.224710</td>\n",
       "      <td>...</td>\n",
       "      <td>2.79864</td>\n",
       "      <td>5.512640</td>\n",
       "      <td>0.042000</td>\n",
       "      <td>-0.048300</td>\n",
       "      <td>-0.035500</td>\n",
       "      <td>-0.026699</td>\n",
       "      <td>0.067301</td>\n",
       "      <td>-0.125101</td>\n",
       "      <td>10.365118</td>\n",
       "      <td>0.148034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ZTF22aabovlw</th>\n",
       "      <td>0.269753</td>\n",
       "      <td>0.002017</td>\n",
       "      <td>0.252035</td>\n",
       "      <td>2.489740</td>\n",
       "      <td>1.080980</td>\n",
       "      <td>0.000083</td>\n",
       "      <td>0.000170</td>\n",
       "      <td>0.000262</td>\n",
       "      <td>6.22435</td>\n",
       "      <td>26.303900</td>\n",
       "      <td>...</td>\n",
       "      <td>6.67416</td>\n",
       "      <td>21.558701</td>\n",
       "      <td>0.225199</td>\n",
       "      <td>0.468000</td>\n",
       "      <td>0.606100</td>\n",
       "      <td>0.483999</td>\n",
       "      <td>0.585100</td>\n",
       "      <td>0.647001</td>\n",
       "      <td>33.811442</td>\n",
       "      <td>4.407910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ZTF22aabovqa</th>\n",
       "      <td>0.297716</td>\n",
       "      <td>-0.012836</td>\n",
       "      <td>0.393293</td>\n",
       "      <td>2.509090</td>\n",
       "      <td>1.159710</td>\n",
       "      <td>0.000032</td>\n",
       "      <td>0.000075</td>\n",
       "      <td>0.000119</td>\n",
       "      <td>6.27272</td>\n",
       "      <td>27.252300</td>\n",
       "      <td>...</td>\n",
       "      <td>4.66721</td>\n",
       "      <td>24.813900</td>\n",
       "      <td>0.164400</td>\n",
       "      <td>0.497700</td>\n",
       "      <td>0.576599</td>\n",
       "      <td>0.519001</td>\n",
       "      <td>0.523500</td>\n",
       "      <td>0.340700</td>\n",
       "      <td>13.564320</td>\n",
       "      <td>0.561596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ZTF22aabovuq</th>\n",
       "      <td>0.263538</td>\n",
       "      <td>-0.005838</td>\n",
       "      <td>0.246578</td>\n",
       "      <td>2.126560</td>\n",
       "      <td>1.055290</td>\n",
       "      <td>0.000066</td>\n",
       "      <td>0.000117</td>\n",
       "      <td>0.000149</td>\n",
       "      <td>5.31639</td>\n",
       "      <td>16.422501</td>\n",
       "      <td>...</td>\n",
       "      <td>4.52423</td>\n",
       "      <td>9.968540</td>\n",
       "      <td>0.208200</td>\n",
       "      <td>0.258701</td>\n",
       "      <td>0.299500</td>\n",
       "      <td>0.200001</td>\n",
       "      <td>0.211201</td>\n",
       "      <td>0.114901</td>\n",
       "      <td>27.004007</td>\n",
       "      <td>4.425228</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5837 rows × 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               gmomentXX  gmomentXY  gmomentYY  gmomentR1  gmomentRH  \\\n",
       "ztf_object_id                                                          \n",
       "ZTF17aaadars    0.182697   0.000057   0.206433   0.899402   0.707021   \n",
       "ZTF17aaahrni    0.395019   0.035295   0.428865   1.574710   0.911899   \n",
       "ZTF17aaaizmo    0.280209   0.020304   0.289936   3.348710   1.155740   \n",
       "ZTF17aabtbti    0.345283  -0.014541   0.300773   1.260110   0.941188   \n",
       "ZTF17aachsxt    0.330886   0.020398   0.289500   1.696890   1.039760   \n",
       "...                  ...        ...        ...        ...        ...   \n",
       "ZTF22aaboeex    0.308624   0.007761   0.309511   3.498180   1.136470   \n",
       "ZTF22aaboiqa    0.271177   0.036831   0.286689   1.241780   0.951537   \n",
       "ZTF22aabovlw    0.269753   0.002017   0.252035   2.489740   1.080980   \n",
       "ZTF22aabovqa    0.297716  -0.012836   0.393293   2.509090   1.159710   \n",
       "ZTF22aabovuq    0.263538  -0.005838   0.246578   2.126560   1.055290   \n",
       "\n",
       "               gPSFFlux   gApFlux  gKronFlux  gKronRad  gExtNSigma  ...  \\\n",
       "ztf_object_id                                                       ...   \n",
       "ZTF17aaadars   0.000008  0.000008   0.000008   2.24851   -0.771992  ...   \n",
       "ZTF17aaahrni   0.000003  0.000008   0.000009   3.93677    8.333380  ...   \n",
       "ZTF17aaaizmo   0.000057  0.000141   0.000310   8.37179   15.204500  ...   \n",
       "ZTF17aabtbti   0.000004  0.000007   0.000007   3.15028    4.822180  ...   \n",
       "ZTF17aachsxt   0.000024  0.000046   0.000051   4.24223   18.275499  ...   \n",
       "...                 ...       ...        ...       ...         ...  ...   \n",
       "ZTF22aaboeex   0.000074  0.000165   0.000340   8.74544   24.032301  ...   \n",
       "ZTF22aaboiqa   0.000035  0.000047   0.000045   3.10445    7.224710  ...   \n",
       "ZTF22aabovlw   0.000083  0.000170   0.000262   6.22435   26.303900  ...   \n",
       "ZTF22aabovqa   0.000032  0.000075   0.000119   6.27272   27.252300  ...   \n",
       "ZTF22aabovuq   0.000066  0.000117   0.000149   5.31639   16.422501  ...   \n",
       "\n",
       "               yKronRad  yExtNSigma       i-z  gApMag_gKronMag  \\\n",
       "ztf_object_id                                                    \n",
       "ZTF17aaadars    2.28946    0.923409  0.257099        -0.120399   \n",
       "ZTF17aaahrni    2.43505    6.442500  0.096600         0.164299   \n",
       "ZTF17aaaizmo    5.85443   28.151199  0.027800         0.855101   \n",
       "ZTF17aabtbti    2.25483    3.383140  0.175501        -0.055199   \n",
       "ZTF17aachsxt    3.51504   20.063499 -0.094900         0.122499   \n",
       "...                 ...         ...       ...              ...   \n",
       "ZTF22aaboeex    6.76913   26.586201  0.233500         0.784500   \n",
       "ZTF22aaboiqa    2.79864    5.512640  0.042000        -0.048300   \n",
       "ZTF22aabovlw    6.67416   21.558701  0.225199         0.468000   \n",
       "ZTF22aabovqa    4.66721   24.813900  0.164400         0.497700   \n",
       "ZTF22aabovuq    4.52423    9.968540  0.208200         0.258701   \n",
       "\n",
       "               rApMag_rKronMag  iApMag_iKronMag  zApMag_zKronMag  \\\n",
       "ztf_object_id                                                      \n",
       "ZTF17aaadars         -0.177700        -0.116199        -0.128300   \n",
       "ZTF17aaahrni         -0.071001         0.051300        -0.024000   \n",
       "ZTF17aaaizmo          0.652599         0.618401         0.684500   \n",
       "ZTF17aabtbti          0.066099        -0.006701        -0.024200   \n",
       "ZTF17aachsxt          0.208000         0.324200         0.378099   \n",
       "...                        ...              ...              ...   \n",
       "ZTF22aaboeex          0.708401         0.683500         0.644199   \n",
       "ZTF22aaboiqa         -0.035500        -0.026699         0.067301   \n",
       "ZTF22aabovlw          0.606100         0.483999         0.585100   \n",
       "ZTF22aabovqa          0.576599         0.519001         0.523500   \n",
       "ZTF22aabovuq          0.299500         0.200001         0.211201   \n",
       "\n",
       "               yApMag_yKronMag       7DCD   dist/DLR  \n",
       "ztf_object_id                                         \n",
       "ZTF17aaadars         -0.208900  48.409333   0.063386  \n",
       "ZTF17aaahrni         -0.145601  22.882911   2.639232  \n",
       "ZTF17aaaizmo          0.695499  14.803999   4.788567  \n",
       "ZTF17aabtbti         -0.064001   5.578753  11.742125  \n",
       "ZTF17aachsxt          0.192301  45.767392   4.255986  \n",
       "...                        ...        ...        ...  \n",
       "ZTF22aaboeex          0.548500  25.406284   1.134230  \n",
       "ZTF22aaboiqa         -0.125101  10.365118   0.148034  \n",
       "ZTF22aabovlw          0.647001  33.811442   4.407910  \n",
       "ZTF22aabovqa          0.340700  13.564320   0.561596  \n",
       "ZTF22aabovuq          0.114901  27.004007   4.425228  \n",
       "\n",
       "[5837 rows x 58 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_bank = pd.read_csv('../loci_dbs/alerce_cut/dataset_bank.csv.gz', compression='gzip', index_col=0)\n",
    "host_dataset_bank = dataset_bank[feature_names_hostgal]\n",
    "host_dataset_bank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "938cf630",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gmomentXX 0.3279579877853393\n",
      "gmomentXY 0.000289833988063\n",
      "gmomentYY 0.3296020030975342\n",
      "gmomentR1 2.16513991355896\n",
      "gmomentRH 1.1088800430297852\n",
      "gPSFFlux 4.122230166103691e-05\n",
      "gApFlux 8.937210077419877e-05\n",
      "gKronFlux 0.0001254280068678\n",
      "gKronRad 5.4128499031066895\n",
      "gExtNSigma 20.0137996673584\n",
      "rmomentXX 0.2744059860706329\n",
      "rmomentXY 0.000149056999362\n",
      "rmomentYY 0.2736389935016632\n",
      "rmomentR1 2.2395999431610107\n",
      "rmomentRH 1.0743399858474731\n",
      "rPSFFlux 6.563430360984057e-05\n",
      "rApFlux 0.0001446600072085\n",
      "rKronFlux 0.0002102949947584\n",
      "rKronRad 5.598999977111816\n",
      "rExtNSigma 19.280000686645508\n",
      "imomentXX 0.2426429986953735\n",
      "imomentXY 0.0001063829986378\n",
      "imomentYY 0.2424930036067962\n",
      "imomentR1 2.25954008102417\n",
      "imomentRH 1.0501999855041504\n",
      "iPSFFlux 8.896220242604613e-05\n",
      "iApFlux 0.0001902249932754\n",
      "iKronFlux 0.000290505005978\n",
      "iKronRad 5.648849964141846\n",
      "iExtNSigma 16.920400619506836\n",
      "zmomentXX 0.2212350070476532\n",
      "zmomentXY 3.861559889628552e-05\n",
      "zmomentYY 0.2217189967632293\n",
      "zmomentR1 2.048959970474243\n",
      "zmomentRH 1.014899969100952\n",
      "zPSFFlux 0.0001017019967548\n",
      "zApFlux 0.0002209560043411\n",
      "zKronFlux 0.0003317749942652\n",
      "zKronRad 5.122399806976318\n",
      "zExtNSigma 20.039899826049805\n",
      "ymomentXX 0.2184389978647232\n",
      "ymomentXY 0.0003275309863965\n",
      "ymomentYY 0.2187229990959167\n",
      "ymomentR1 1.7396899461746216\n",
      "ymomentRH 0.9847790002822876\n",
      "yPSFFlux 0.0001208190005854\n",
      "yApFlux 0.00025407699286\n",
      "yKronFlux 0.000349478010321\n",
      "yKronRad 4.349219799041748\n",
      "yExtNSigma 17.576799392700195\n",
      "i-z 0.1674995422363281\n",
      "gApMag_gKronMag 0.2904014587402344\n",
      "rApMag_rKronMag 0.3589992523193359\n",
      "iApMag_iKronMag 0.3936996459960937\n",
      "zApMag_zKronMag 0.3745002746582031\n",
      "yApMag_yKronMag 0.2802009582519567\n",
      "7DCD 29.74364476624636\n",
      "dist/DLR 0.4173076149751359\n"
     ]
    }
   ],
   "source": [
    "median_host_vals_dict = {}\n",
    "\n",
    "for f in host_dataset_bank.columns:\n",
    "    median_val = np.median(host_dataset_bank[f])\n",
    "    print(f, median_val)\n",
    "    median_host_vals_dict[f] = median_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1234fdd4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6b731779",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLS CART\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLS ILOT\n",
      "CLS KN_B19\n",
      "CLS PISN-MOSFIT\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-98c472c45819>\u001b[0m in \u001b[0;36mextract_lc_features\u001b[0;34m(k2, lightcurve)\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0;31m# Drop NaNs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m     \u001b[0mlc_properties_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlc_properties_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mlc_properties_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mlc_properties_df\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/laiss/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36misnull\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   5032\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNDFrame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misna\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mklass\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_shared_doc_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"klass\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5033\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0misnull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5034\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5035\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5036\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNDFrame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnotna\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mklass\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_shared_doc_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"klass\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/laiss/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36misna\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   5027\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNDFrame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misna\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mklass\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_shared_doc_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"klass\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5028\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0misna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5029\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_constructor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mgr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0misna\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5030\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__finalize__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"isna\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5031\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/laiss/lib/python3.8/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36misna\u001b[0;34m(self, func)\u001b[0m\n\u001b[1;32m    544\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    545\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0misna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;34m\"BlockManager\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 546\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"apply\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    547\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m     def where(\n",
      "\u001b[0;32m~/miniconda3/envs/laiss/lib/python3.8/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, f, align_keys, ignore_failures, **kwargs)\u001b[0m\n\u001b[1;32m    425\u001b[0m                     \u001b[0mapplied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 427\u001b[0;31m                     \u001b[0mapplied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    428\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mignore_failures\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/laiss/lib/python3.8/site-packages/pandas/core/internals/blocks.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, **kwargs)\u001b[0m\n\u001b[1;32m    378\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    379\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 380\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_split_op_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    381\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    382\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_failures\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Block\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/laiss/lib/python3.8/site-packages/pandas/core/internals/blocks.py\u001b[0m in \u001b[0;36m_split_op_result\u001b[0;34m(self, result)\u001b[0m\n\u001b[1;32m    414\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    415\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBlock\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 416\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_block\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    417\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    418\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/laiss/lib/python3.8/site-packages/pandas/core/internals/blocks.py\u001b[0m in \u001b[0;36mmake_block\u001b[0;34m(self, values, placement)\u001b[0m\n\u001b[1;32m    284\u001b[0m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_block_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mndim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 286\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmake_block\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplacement\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mplacement\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mndim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    287\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmake_block_same_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplacement\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mndim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/laiss/lib/python3.8/site-packages/pandas/core/internals/blocks.py\u001b[0m in \u001b[0;36mmake_block\u001b[0;34m(values, placement, klass, ndim, dtype)\u001b[0m\n\u001b[1;32m   2733\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mklass\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2734\u001b[0m         \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2735\u001b[0;31m         \u001b[0mklass\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_block_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2736\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2737\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mklass\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mDatetimeTZBlock\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_datetime64tz_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/laiss/lib/python3.8/site-packages/pandas/core/internals/blocks.py\u001b[0m in \u001b[0;36mget_block_type\u001b[0;34m(values, dtype)\u001b[0m\n\u001b[1;32m   2698\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mis_datetime64tz_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2699\u001b[0m         \u001b[0mcls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDatetimeTZBlock\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2700\u001b[0;31m     \u001b[0;32melif\u001b[0m \u001b[0mis_interval_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mis_period_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2701\u001b[0m         \u001b[0mcls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mObjectValuesExtensionBlock\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2702\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mis_extension_array_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/laiss/lib/python3.8/site-packages/pandas/core/dtypes/common.py\u001b[0m in \u001b[0;36mis_interval_dtype\u001b[0;34m(arr_or_dtype)\u001b[0m\n\u001b[1;32m    532\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0marr_or_dtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    533\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 534\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mIntervalDtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr_or_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    535\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    536\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/laiss/lib/python3.8/site-packages/pandas/core/dtypes/dtypes.py\u001b[0m in \u001b[0;36mis_dtype\u001b[0;34m(cls, dtype)\u001b[0m\n\u001b[1;32m   1147\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1148\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1149\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m     def __from_arrow__(\n",
      "\u001b[0;32m~/miniconda3/envs/laiss/lib/python3.8/site-packages/pandas/core/dtypes/base.py\u001b[0m in \u001b[0;36mis_dtype\u001b[0;34m(cls, dtype)\u001b[0m\n\u001b[1;32m    278\u001b[0m         \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"dtype\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 280\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mABCSeries\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mABCIndexClass\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mABCDataFrame\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    281\u001b[0m             \u001b[0;31m# https://github.com/pandas-dev/pandas/issues/22960\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m             \u001b[0;31m# avoid passing data to `construct_from_string`. This could\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/laiss/lib/python3.8/site-packages/pandas/core/dtypes/generic.py\u001b[0m in \u001b[0;36m_check\u001b[0;34m(cls, inst)\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_check\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minst\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"_typ\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcomp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0mdct\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"__instancecheck__\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0m_check\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"__subclasscheck__\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0m_check\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "uniq_cls_l = ['CART', 'ILOT', 'KN_B19', 'PISN-MOSFIT', 'PISN-STELLA_HECORE',\n",
    "       'PISN-STELLA_HYDROGENIC', 'SLSNI', 'SNII', 'SNIIn+HostXT',\n",
    "       'SNIIn-MOSFIT', 'SNIa', 'SNIa-91bg', 'SNIax', 'SNIb', 'SNIc',\n",
    "       'SNIcBL+HostXT_V19', 'TDE']\n",
    "uniq_key_l = ['HOSTGAL_MAGERR_g', 'Filter', 'MAGERR', 'HOSTGAL_MAG_i', 'Flux_Err', \n",
    "'HOSTGAL_MAG_g', 'MJD', 'MAG', 'HOSTGAL_PHOTOZ', 'MWEBV', 'REDSHIFT_HELIO', \n",
    "'HOSTGAL_PHOTOZ_ERR', 'HOSTGAL_MAGERR_z', 'Flux', 'HOSTGAL_DDLR', 'MJD_TRIGGER', \n",
    "'Type', 'SIM_HOSTLIB_GALID', 'HOSTGAL_MAG_r', 'HOSTGAL_MAG_z', 'HOSTGAL_MAGERR_i', 'HOSTGAL_MAGERR_r']\n",
    "\n",
    "master_dict = dict()\n",
    "num = 0\n",
    "num_inspect = 100\n",
    "for cls in uniq_cls_l:\n",
    "    print(\"CLS\", cls)\n",
    "    cls_galid_d = dict()\n",
    "    for k, v in data.items():\n",
    "        if k == 'Type':\n",
    "            for k2, v2 in v.items():\n",
    "                if v2 == cls: #\"CART\"\n",
    "                    num += 1\n",
    "                    #if num > num_inspect: \n",
    "                    #    break\n",
    "                    cls_galid_d[k2] = \"Observed\" # do True/False if it passes AD model or not\n",
    "                    uniq_pbs = np.unique(data[\"Filter\"].get(k2))\n",
    "                    if len(uniq_pbs) <= 1:\n",
    "                        cls_galid_d[k2] = \"FailCuts\"\n",
    "                        master_dict[cls] = cls_galid_d\n",
    "                        continue\n",
    "\n",
    "                    # run LC feat extractor\n",
    "                    lightcurve = pd.DataFrame(zip(data[\"MJD\"].get(k2), data[\"Filter\"].get(k2), data[\"Flux\"].get(k2), \n",
    "                                                  data[\"Flux_Err\"].get(k2), data[\"MAG\"].get(k2), data[\"MAGERR\"].get(k2)),\n",
    "                                    columns=['MJD', 'Filter', 'Flux', 'Flux_Err', 'MAG', 'MAGERR'])\n",
    "\n",
    "                    try:\n",
    "                        lc_properties_df = extract_lc_features(k2=k2, lightcurve=lightcurve)\n",
    "                        lc_and_hosts_df_120d = lc_properties_df[feature_names_r_g]\n",
    "                    except Exception as e:\n",
    "                        #print(e)\n",
    "                        cls_galid_d[k2] = \"FailCuts\"\n",
    "                        master_dict[cls] = cls_galid_d\n",
    "\n",
    "\n",
    "                    # Convert host features into those that the model can run on\n",
    "                    for h_feat in feature_names_hostgal:\n",
    "                        #print(h_feat, median_host_vals_dict.get(h_feat))\n",
    "                        lc_and_hosts_df_120d[h_feat] = median_host_vals_dict.get(h_feat)\n",
    "\n",
    "\n",
    "                    # run AD model\n",
    "                    #print(lc_and_hosts_df_120d, lc_and_hosts_df_120d)\n",
    "                    k2, anom_idx_is = plot_RFC_prob_vs_lc_ztfid(clf=clf, \n",
    "                                              k2=k2, \n",
    "                                              cls=v2, \n",
    "                                              photoz=round(data[\"HOSTGAL_PHOTOZ\"].get(k2), 3), \n",
    "                                              anom_thresh=50, \n",
    "                                              lc_and_hosts_df=lc_properties_df, \n",
    "                                              lc_and_hosts_df_120d=lc_and_hosts_df_120d, \n",
    "                                              lightcurve=lightcurve, \n",
    "                                              savefig=False, \n",
    "                                              figure_path=\"Abc\", \n",
    "                                              plot=False)\n",
    "\n",
    "                    if anom_idx_is == \"Normal\":\n",
    "                        cls_galid_d[k2] = \"Normal\"\n",
    "                    elif anom_idx_is == \"Anomaly\":\n",
    "                        cls_galid_d[k2] = \"Anomaly\"\n",
    "                    else:\n",
    "                        cls_galid_d[k2] = \"???\"\n",
    "                        \n",
    "                    master_dict[cls] = cls_galid_d\n",
    "\n",
    "#     # if passes, keep Tagged. Else, not Tagged\n",
    "# cls_l, num_anom_tagged_l, num_anom_generated_l, anom_recovered_percent_l = [],[],[],[]\n",
    "# print(\"Tally:\", Counter(cls_galid_d.values()))\n",
    "# num_anom_tagged = (Counter(cls_galid_d.values()).get('Anomaly'))\n",
    "# num_anom_generated = anomaly_distr_d.get(cls)\n",
    "# anom_recovered_percent = round((num_anom_tagged/num_anom_generated)*100, 3)\n",
    "# print(f\"Anomaly % recovered: {num_anom_tagged}/{num_anom_generated}% = {anom_recovered_percent}%\")\n",
    "# cls_l.append(cls), num_anom_tagged_l.append(num_anom_tagged)\n",
    "# num_anom_generated_l.append(num_anom_generated), anom_recovered_percent_l.append(anom_recovered_percent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a6cf3713",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CART\n",
      "Tally: Counter({'Normal': 63, 'Anomaly': 27})\n",
      "Anomaly % recovered: 27/90% = 30.0%\n",
      "ILOT\n",
      "Tally: Counter({'FailCuts': 1})\n",
      "Anomaly % recovered: 0/1% = 0.0%\n",
      "KN_B19\n",
      "Tally: Counter({'Normal': 2})\n",
      "Anomaly % recovered: 0/2% = 0.0%\n",
      "PISN-MOSFIT\n",
      "Tally: Counter({'Normal': 60, 'Anomaly': 20, 'Observed': 1})\n",
      "Anomaly % recovered: 20/4152% = 0.5%\n"
     ]
    }
   ],
   "source": [
    "cls_l, num_anom_tagged_l, num_anom_generated_l, anom_recovered_percent_l,  num_failcuts_l = [],[],[],[],[]\n",
    "\n",
    "for cls in master_dict.keys():\n",
    "    print(cls)\n",
    "    print(\"Tally:\", Counter(master_dict.get(cls).values()))\n",
    "    num_anom_tagged = (Counter(master_dict.get(cls).values()).get('Anomaly')) \n",
    "    num_anom_generated = anomaly_distr_d.get(cls)\n",
    "    try:\n",
    "        anom_recovered_percent = round((num_anom_tagged/num_anom_generated), 3)*100\n",
    "    except:\n",
    "        num_anom_tagged = 0\n",
    "        anom_recovered_percent = round((num_anom_tagged/num_anom_generated), 3)*100\n",
    "    print(f\"Anomaly % recovered: {num_anom_tagged}/{num_anom_generated}% = {anom_recovered_percent}%\")\n",
    "    num_failcuts = (Counter(master_dict.get(cls).values()).get('FailCuts'))\n",
    "    \n",
    "    if num_failcuts is None:\n",
    "        num_failcuts = 0\n",
    "    \n",
    "    cls_l.append(cls), num_anom_tagged_l.append(num_anom_tagged)\n",
    "    num_anom_generated_l.append(num_anom_generated), anom_recovered_percent_l.append(anom_recovered_percent), num_failcuts_l.append(num_failcuts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9d3911b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cls</th>\n",
       "      <th>num_anom_tagged</th>\n",
       "      <th>num_anom_generated</th>\n",
       "      <th>anom_recovered_percent</th>\n",
       "      <th>num_failcuts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CART</td>\n",
       "      <td>27</td>\n",
       "      <td>90</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ILOT</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>KN_B19</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PISN-MOSFIT</td>\n",
       "      <td>20</td>\n",
       "      <td>4152</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           cls  num_anom_tagged  num_anom_generated  anom_recovered_percent  \\\n",
       "0         CART               27                  90                    30.0   \n",
       "1         ILOT                0                   1                     0.0   \n",
       "2       KN_B19                0                   2                     0.0   \n",
       "3  PISN-MOSFIT               20                4152                     0.5   \n",
       "\n",
       "   num_failcuts  \n",
       "0             0  \n",
       "1             1  \n",
       "2             0  \n",
       "3             0  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anom_recover_df = pd.DataFrame(zip(cls_l, num_anom_tagged_l, num_anom_generated_l, anom_recovered_percent_l, num_failcuts_l),\n",
    "                              columns=[\"cls\", \"num_anom_tagged\", \"num_anom_generated\", \"anom_recovered_percent\", \"num_failcuts\"])\n",
    "anom_recover_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6c3bb6e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "laiss",
   "language": "python",
   "name": "laiss"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
